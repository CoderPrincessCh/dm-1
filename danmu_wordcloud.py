import requests
import xml.etree.ElementTree as ET
from wordcloud import WordCloud
import jieba
import matplotlib.pyplot as plt

SEARCH_API = "https://www.missevan.com/sound/getsearch"
DANMU_API = "https://www.missevan.com/sound/getdm"

def search_drama(keyword: str):
    page = 1
    page_size = 30
    collected = []
    keyword_lower = keyword.strip().lower()

    while True:
        params = {
            "s": keyword,
            "p": page,
            "type": 3,
            "page_size": page_size
        }
        try:
            response = requests.get(SEARCH_API, params=params)
            response.raise_for_status()
            data = response.json()
            datas = data.get("info", {}).get("Datas", [])
            filtered = [
                (item["id"], item["soundstr"])
                for item in datas
                # if item.get("pay_type") == "2"
                # and keyword_lower in item.get("soundstr", "").lower()
                if keyword_lower in item.get("soundstr", "").lower()
            ]
            collected.extend(filtered)

            if len(datas) < page_size:
                break
            page += 1
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥ï¼š{e}")
            break
    return collected

def fetch_all_danmu_text(drama_list):
    all_texts = []
    for soundid, name in drama_list:
        print(f"â†’ èŽ·å–ï¼š{name} (ID: {soundid})")
        try:
            response = requests.get(DANMU_API, params={"soundid": soundid})
            response.raise_for_status()
            xml_text = response.text
            root = ET.fromstring(xml_text)
            for d in root.findall("d"):
                all_texts.append(d.text or "")
        except Exception as e:
            print(f"âŒ èŽ·å–å¤±è´¥ï¼ˆID={soundid}ï¼‰ï¼š{e}")
    return all_texts

def generate_wordcloud(danmu_list, filename="danmu_wordcloud.png"):
    if not danmu_list:
        print("âš ï¸ æ²¡æœ‰å¼¹å¹•å†…å®¹")
        return

    print("ðŸŽ¨ æ­£åœ¨ç”Ÿæˆè¯äº‘...")
    text = " ".join(jieba.cut(" ".join(danmu_list)))
    wc = WordCloud(
        font_path="msyh.ttc",  # æ›¿æ¢ä¸ºç³»ç»Ÿçš„ä¸­æ–‡å­—ä½“è·¯å¾„
        width=1000,
        height=600,
        background_color="white",
        max_words=300
    ).generate(text)

    wc.to_file(filename)
    print(f"âœ… è¯äº‘å·²ä¿å­˜ä¸º â†’ {filename}")
    plt.imshow(wc, interpolation="bilinear")
    plt.axis("off")
    plt.show()

def main():
    keyword = input("è¯·è¾“å…¥å‰§åå…³é”®è¯ï¼š").strip()
    if not keyword:
        print("âš ï¸ å…³é”®è¯ä¸èƒ½ä¸ºç©º")
        return

    print("ðŸ” æ­£åœ¨æœç´¢å‰§é›†...")
    drama_list = search_drama(keyword)
    if not drama_list:
        print("âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å‰§é›†")
        return

    print(f"\nðŸŽ¬ å…±æ‰¾åˆ° {len(drama_list)} ä¸ªä»˜è´¹å‰§é›†ï¼š")
    for _, name in drama_list:
        print(" -", name)

    print("\nðŸ“¥ æ­£åœ¨èŽ·å–æ‰€æœ‰å®žæ—¶å¼¹å¹•...")
    all_text = fetch_all_danmu_text(drama_list)
    print(f"ðŸ”¹ å…±æ”¶é›† {len(all_text)} æ¡å¼¹å¹•")

    generate_wordcloud(all_text)

    input("\nâœ… æ“ä½œå®Œæˆï¼ŒæŒ‰å›žè½¦é€€å‡º...")

if __name__ == "__main__":
    main()
