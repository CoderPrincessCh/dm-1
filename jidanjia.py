import requests
import re
import csv
from time import sleep
from html import unescape

DRAMALIST_API = "https://www.missevan.com/dramaapi/filter"
SEARCH_API = "https://www.missevan.com/dramaapi/search"
headers = {
    "User-Agent": "Mozilla/5.0"
}

def clean_html(raw_html):
    # å»é™¤ HTML æ ‡ç­¾
    text = re.sub(r"<.*?>", "", raw_html)
    return unescape(text)

def extract_producers(abstract_html: str):
    text = clean_html(abstract_html)

    # æå–â€œè”åˆå‡ºå“â€ã€â€œå‡ºå“â€ã€â€œè”åˆåˆ¶ä½œâ€ ç­‰å¥å­
    match = re.search(r"(çŒ«è€³FM.*?å‡ºå“|.*?è”åˆå‡ºå“|.*?å‡ºå“)", text)
    producers = match.group(0).strip() if match else ""

    has_maoer = "çŒ«è€³FM" in producers
    return producers, "æ˜¯" if has_maoer else "å¦"

def extract_episode_counts(abstract_html: str):
    text = clean_html(abstract_html)

    # ä¼˜å…ˆåŒ¹é…ï¼š9é›†æ­£å‰§ + 4ä¸ªç•ªå¤–
    combo_match = re.search(
        r"(\d+)\s*[é›†è¯æœŸ]+\s*æ­£å‰§\s*[,ã€ï¼Œ\s]*\s*(\d+)\s*[é›†è¯æœŸ]*\s*(ç•ªå¤–|èŠ±çµ®|å°å‰§åœº|ç¦åˆ©)?",
        text
    )
    if combo_match:
        main_eps = int(combo_match.group(1))
        extra_eps = int(combo_match.group(2))
        total_eps = main_eps + extra_eps
    else:
        # åŒ¹é…ï¼šå…±Xé›†æ­£å‰§ / æ­£å‰§Xé›†
        alt_main_match = re.search(r"(?:æ­£å‰§\s*å…±?|å…±\s*)?(\d+)\s*[é›†è¯æœŸ]\s*æ­£å‰§", text)
        if alt_main_match:
            main_eps = int(alt_main_match.group(1))
            total_eps = main_eps
        else:
            # åŒ¹é…ï¼šå…±Xé›†ï¼ˆæ€»é›†æ•°ï¼‰
            total_match = re.search(r"å…±\s*(\d+)\s*[é›†è¯æœŸ]", text)
            total_eps = int(total_match.group(1)) if total_match else None

            # åŒ¹é…ï¼šå«Xé›†ç•ªå¤–ç­‰
            extra_match = re.search(r"å«\s*(\d+)\s*[é›†è¯æœŸ]?.*?(ç•ªå¤–|èŠ±çµ®|å°å‰§åœº|ç¦åˆ©)", text)
            extra_eps = int(extra_match.group(1)) if extra_match else 0

            main_eps = total_eps - extra_eps if total_eps is not None else None

    # æå–â€œå‰Xé›†å…è´¹â€
    free_match = re.search(r"(?:å‰|é¦–)\s*(\d+)\s*[é›†è¯æœŸ]?.*?(å…è´¹|é™å…)", text)
    free_eps = int(free_match.group(1)) if free_match else 0

    # ä»˜è´¹é›†æ•° = æ­£å‰§ - å…è´¹é›†æ•°ï¼ˆä¸èƒ½å°äº0ï¼‰
    if main_eps is not None:
        paid_eps = max(main_eps - free_eps, 0)
    else:
        paid_eps = None

    return total_eps, main_eps, paid_eps


def fetch_drama_list_page(page: int):
    url = f"{DRAMALIST_API}?filters=0_0_0_0&page={page}&order=1&page_size=20&type=3"
    resp = requests.get(url, headers=headers, timeout=10)
    resp.raise_for_status()
    return resp.json()["info"]["Datas"]

def fetch_all_seasons_by_name(drama_name: str):
    """
    æ ¹æ®ä¸»å‰§åæœç´¢ï¼Œè¿”å›æ‰€æœ‰åŒ¹é…å‰§ï¼ˆåŒ…å«å¤šå­£ï¼‰ï¼Œ
    è¿”å›åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ dictï¼ŒåŒ…å«ä»·æ ¼ã€é›†æ•°ã€åå­—ã€abstract
    """
    params = {"s": drama_name, "page": 1}
    resp = requests.get(SEARCH_API, headers=headers, params=params, timeout=10)
    resp.raise_for_status()
    candidates = resp.json()["info"]["Datas"]

    results = []
    for item in candidates:
        name = item.get("name", "")
        price_diamond = item.get("price", 0)

        # åªä¿ç•™ä»·æ ¼å¤§äº0çš„
        if price_diamond <= 0:
            continue

        # è¿‡æ»¤åªè¦åŒ…å«ä¸»å‰§åçš„ç»“æœ
        if drama_name in name:
            abstract = item.get("abstract", "")
            total_eps, main_eps, paid_eps = extract_episode_counts(abstract)
            results.append({
                "å‰§å": name,
                "ä»·æ ¼é’»çŸ³": price_diamond,
                "æ€»é›†æ•°": total_eps,
                "æ­£å‰§é›†æ•°": main_eps,
                "abstract": abstract,
                "ä»˜è´¹é›†æ•°": paid_eps,
            })

    if not results:
        print(f"âš ï¸ æœªæ‰¾åˆ°åŒ¹é…å‰§ç›®: {drama_name}")
    return results


def clean_drama_name(name: str) -> str:
    """
    å»æ‰â€œç¬¬Xå­£â€ã€â€œä¸Šå­£â€ã€â€œä¸‹å­£â€ã€â€œå…¨ä¸€å­£â€ã€â€œåˆé›†â€ç­‰åç¼€ï¼Œä»…ä¿ç•™ä¸»å‰§å
    """
    return re.sub(r"[\sÂ·]*(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å1234567890]+å­£|å…¨[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å1234567890]+å­£|ä¸Šå­£|ä¸‹å­£|åˆé›†)$", "", name).strip()


def process_one_drama(drama):
    raw_name = drama["name"]
    drama_name = clean_drama_name(raw_name)
    drama_id = drama["id"]

    all_seasons = fetch_all_seasons_by_name(drama_name)
    results = []

    if not all_seasons:
        print(f"âš ï¸ {raw_name} æœªæ‰¾åˆ°ä»»ä½•å­£ï¼Œè·³è¿‡")
        return []

    for season in all_seasons:
        price_rmb = season["ä»·æ ¼é’»çŸ³"] / 10
        main_eps = season["æ­£å‰§é›†æ•°"]
        paid_eps = season["ä»˜è´¹é›†æ•°"]

        if paid_eps is None or paid_eps == 0:
            unit_price = 0
        else:
            unit_price = round(price_rmb / paid_eps, 2)

        if main_eps is None or main_eps == 0:
            avg_price = 0
            print(f"âš ï¸ {season['å‰§å']} æ— æ³•è®¡ç®—é›†å‡ä»·ï¼ˆæ­£å‰§æœªçŸ¥æˆ–ä¸º0ï¼‰")
        else:
            avg_price = round(price_rmb / main_eps, 2)

        results.append({
            "å‰§å": season["å‰§å"],
            "å‰§ID": drama_id,
            "æ€»é›†æ•°ï¼ˆå«ç•ªå¤–ï¼‰": season["æ€»é›†æ•°"] if season["æ€»é›†æ•°"] else "æœªçŸ¥",
            "æ­£å‰§é›†æ•°": main_eps if main_eps else "æœªçŸ¥",
            "æ€»ä»·ï¼ˆå…ƒï¼‰": round(price_rmb, 2),
            "é›†å‡ä»·ï¼ˆå…ƒï¼‰": avg_price,
            "ä»˜è´¹é›†æ•°": paid_eps if paid_eps else "æœªçŸ¥",
            "ä»˜è´¹é›†å•ä»·ï¼ˆå…ƒï¼‰": unit_price

        })

    return results

def main(export_csv=True):
    result = []
    page = 1
    max_pages = 100  # æœ€å¤§æŠ“å–é¡µæ•°é™åˆ¶

    while True:
        if page > max_pages:
            print(f"ğŸ“¢ å·²è¾¾åˆ°æœ€å¤§æŠ“å–é¡µæ•° {max_pages}ï¼Œç»“æŸæŠ“å–ã€‚")
            break

        print(f"ğŸ“¦ æ­£åœ¨æŠ“å–ç¬¬ {page} é¡µå‰§åˆ—è¡¨...")
        try:
            dramas = fetch_drama_list_page(page)
        except Exception as e:
            print(f"â— ç¬¬ {page} é¡µè·å–å¤±è´¥ï¼š{e}")
            break

        if not dramas:
            print("âœ… æŠ“å–å®Œæ¯•")
            break

        for drama in dramas:
            if drama.get("pay_type") != 2:
                continue

            season_results = process_one_drama(drama)
            if season_results:
                result.extend(season_results)
                for data in season_results:
                    print(f"âœ… æ”¶å½•ï¼š{data['å‰§å']} | æ­£å‰§{data['æ­£å‰§é›†æ•°']}é›† | é›†å‡ä»·ï¼šÂ¥{data['é›†å‡ä»·ï¼ˆå…ƒï¼‰']}")

            sleep(0.3)

        page += 1
        sleep(0.5)

    if export_csv:
        with open("å…¨éƒ¨ä»˜è´¹å¹¿æ’­å‰§_é›†å‡ä»·ç»Ÿè®¡.csv", "w", newline="", encoding="utf-8-sig") as f:
            writer = csv.DictWriter(f, fieldnames=[
                "å‰§å", "å‰§ID", "æ€»é›†æ•°ï¼ˆå«ç•ªå¤–ï¼‰", "æ­£å‰§é›†æ•°", "ä»˜è´¹é›†æ•°", "æ€»ä»·ï¼ˆå…ƒï¼‰", "é›†å‡ä»·ï¼ˆå…ƒï¼‰", "ä»˜è´¹é›†å•ä»·ï¼ˆå…ƒï¼‰"
            ])
            writer.writeheader()
            writer.writerows(result)
        print("ğŸ“„ å¯¼å‡ºå®Œæˆï¼šå…¨éƒ¨ä»˜è´¹å¹¿æ’­å‰§_é›†å‡ä»·ç»Ÿè®¡.csv")

    return result

if __name__ == "__main__":
    main()
